{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"../..\")\n",
    "\n",
    "from utils import llm_api\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "from tasks.graph import graph_utils\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper models and the final models we want to use for the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = [\n",
    "    \"llama3.1:8b\",\n",
    "    \"mistral:instruct\",\n",
    "    \"qwen2:7b\",\n",
    "    \"deepseek-coder-v2:16b\",\n",
    "    \"gemma2:9b\"\n",
    "]\n",
    "MODEL_NAMES = [\n",
    "    \"Llama3.1:8b\",\n",
    "    \"Mistral:7b\",\n",
    "    \"Qwen2:7b\",\n",
    "    \"DeepSeek-Coder-v2:16b\",\n",
    "    \"Gemma2:9b\"\n",
    "]\n",
    "GOD_MODELS = [\"gpt-4o-mini\", \"gpt-3.5-turbo\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This csv file is the result of running the \"grpah:1.ipynb\" on different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>edge_size</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>vertex</th>\n",
       "      <th>diff</th>\n",
       "      <th>original_prompt</th>\n",
       "      <th>generated_prompt</th>\n",
       "      <th>god_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gemma2:9b</td>\n",
       "      <td>56</td>\n",
       "      <td>naive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...</td>\n",
       "      <td>[[0, 18], [0, 3], [0, 5], [0, 10], [0, 15], [0...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gemma2:9b</td>\n",
       "      <td>56</td>\n",
       "      <td>opt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...</td>\n",
       "      <td>[[0, 18], [0, 3], [0, 5], [0, 10], [0, 15], [0...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gemma2:9b</td>\n",
       "      <td>56</td>\n",
       "      <td>no_opt</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...</td>\n",
       "      <td>[[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gemma2:9b</td>\n",
       "      <td>56</td>\n",
       "      <td>naive</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...</td>\n",
       "      <td>[[0, 5], [5, 17], [3, 5], [5, 19], [5, 15], [5...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gemma2:9b</td>\n",
       "      <td>56</td>\n",
       "      <td>opt</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...</td>\n",
       "      <td>[[0, 5], [5, 17], [3, 5], [5, 19], [5, 15], [5...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model  edge_size algorithm  vertex  diff  \\\n",
       "0  gemma2:9b         56     naive       0     0   \n",
       "1  gemma2:9b         56       opt       0     0   \n",
       "2  gemma2:9b         56    no_opt       0     1   \n",
       "3  gemma2:9b         56     naive       5     1   \n",
       "4  gemma2:9b         56       opt       5     0   \n",
       "\n",
       "                                     original_prompt  \\\n",
       "0  [[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...   \n",
       "1  [[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...   \n",
       "2  [[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...   \n",
       "3  [[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...   \n",
       "4  [[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...   \n",
       "\n",
       "                                    generated_prompt      god_model  \n",
       "0  [[0, 18], [0, 3], [0, 5], [0, 10], [0, 15], [0...  gpt-3.5-turbo  \n",
       "1  [[0, 18], [0, 3], [0, 5], [0, 10], [0, 15], [0...  gpt-3.5-turbo  \n",
       "2  [[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...  gpt-3.5-turbo  \n",
       "3  [[0, 5], [5, 17], [3, 5], [5, 19], [5, 15], [5...  gpt-3.5-turbo  \n",
       "4  [[0, 5], [5, 17], [3, 5], [5, 19], [5, 15], [5...  gpt-3.5-turbo  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/graph/graph_results.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank Utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the Ranking utility of each of the helper models. In other words, how good they are in estimating the relevance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5600/5600 [00:00<00:00, 8210.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rank_utility</th>\n",
       "      <th>edge_size</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>vertex</th>\n",
       "      <th>diff</th>\n",
       "      <th>original_prompt</th>\n",
       "      <th>generated_prompt</th>\n",
       "      <th>god_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gemma2:9b</td>\n",
       "      <td>2.717857</td>\n",
       "      <td>56</td>\n",
       "      <td>naive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...</td>\n",
       "      <td>[[0, 18], [0, 3], [0, 5], [0, 10], [0, 15], [0...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gemma2:9b</td>\n",
       "      <td>2.717857</td>\n",
       "      <td>56</td>\n",
       "      <td>opt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...</td>\n",
       "      <td>[[0, 18], [0, 3], [0, 5], [0, 10], [0, 15], [0...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gemma2:9b</td>\n",
       "      <td>1.382315</td>\n",
       "      <td>56</td>\n",
       "      <td>no_opt</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...</td>\n",
       "      <td>[[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gemma2:9b</td>\n",
       "      <td>2.592857</td>\n",
       "      <td>56</td>\n",
       "      <td>naive</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...</td>\n",
       "      <td>[[0, 5], [5, 17], [3, 5], [5, 19], [5, 15], [5...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gemma2:9b</td>\n",
       "      <td>2.592857</td>\n",
       "      <td>56</td>\n",
       "      <td>opt</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...</td>\n",
       "      <td>[[0, 5], [5, 17], [3, 5], [5, 19], [5, 15], [5...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model  rank_utility  edge_size algorithm  vertex  diff  \\\n",
       "0  gemma2:9b      2.717857         56     naive       0     0   \n",
       "1  gemma2:9b      2.717857         56       opt       0     0   \n",
       "2  gemma2:9b      1.382315         56    no_opt       0     1   \n",
       "3  gemma2:9b      2.592857         56     naive       5     1   \n",
       "4  gemma2:9b      2.592857         56       opt       5     0   \n",
       "\n",
       "                                     original_prompt  \\\n",
       "0  [[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...   \n",
       "1  [[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...   \n",
       "2  [[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...   \n",
       "3  [[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...   \n",
       "4  [[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...   \n",
       "\n",
       "                                    generated_prompt      god_model  \n",
       "0  [[0, 18], [0, 3], [0, 5], [0, 10], [0, 15], [0...  gpt-3.5-turbo  \n",
       "1  [[0, 18], [0, 3], [0, 5], [0, 10], [0, 15], [0...  gpt-3.5-turbo  \n",
       "2  [[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...  gpt-3.5-turbo  \n",
       "3  [[0, 5], [5, 17], [3, 5], [5, 19], [5, 15], [5...  gpt-3.5-turbo  \n",
       "4  [[0, 5], [5, 17], [3, 5], [5, 19], [5, 15], [5...  gpt-3.5-turbo  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_utils = []\n",
    "for i, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    ut = graph_utils.rank_utility(\n",
    "        json.loads(row[\"generated_prompt\"]),\n",
    "        row[\"vertex\"]\n",
    "    )\n",
    "    rank_utils.append(ut)\n",
    "\n",
    "data.insert(loc=1, column=\"rank_utility\", value=rank_utils)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\n",
    "    \"naive\": \"Warm-up\",\n",
    "    \"bi_graph\": \"Bipartite\",\n",
    "    \"opt\": \"Opt\",\n",
    "    \"no_opt\": \"Random\"\n",
    "}\n",
    "\n",
    "def plot_scores(focused_model):\n",
    "    df = data[(data[\"model\"] == focused_model) \n",
    "                & (data[\"god_model\"] == \"gpt-3.5-turbo\")]\n",
    "    df = df[[\"rank_utility\", \"edge_size\", \"algorithm\", \"diff\"]]\n",
    "    df = df.groupby([\"edge_size\", \"algorithm\"]).mean().reset_index()\n",
    "    \n",
    "    for algorithm in df[\"algorithm\"].unique():\n",
    "        tmp = df[df[\"algorithm\"] == algorithm]\n",
    "        plt.plot(\n",
    "            [str(x) for x in tmp[\"edge_size\"]],\n",
    "            tmp[\"rank_utility\"],\n",
    "            label=labels[algorithm],\n",
    "            marker=\"o\",\n",
    "            markersize=6\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"# of edges\", fontsize=12)\n",
    "    plt.ylabel(\"Ranking Utility\", fontsize=12)\n",
    "    plt.title(\"$\\mathcal{H}$ = \" + MODEL_NAMES[MODELS.index(focused_model)], fontsize=12);\n",
    "    # plt.legend();\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "for model_index, model in enumerate(MODELS):\n",
    "    plt.subplot(1, 4, model_index + 1)\n",
    "    plot_scores(model)\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout();\n",
    "# plt.savefig(\"../../figures/graph-rank-util.eps\", format=\"eps\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-rank + Exposure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the exposure discovery results on the final ranking. Here we are not exactly moving each element to the specified exposure position for that one. We are just shifting the sorted list (top-k) to the correct position. For example, for GPT-3.5, sorted value is enough. However, for GPT-4o-Mini, we shift the whole sorted list to right, such that the top-k move from first part to the middle of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5600/5600 [1:09:29<00:00,  1.34it/s] \n"
     ]
    }
   ],
   "source": [
    "exposure_errors = []\n",
    "normal_errors = []\n",
    "\n",
    "for i, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    god_model = row[\"god_model\"]\n",
    "    generated_prompt = json.loads(row[\"generated_prompt\"])\n",
    "    \n",
    "    if row[\"algorithm\"] == \"no_opt\":\n",
    "        random.shuffle(generated_prompt)\n",
    "\n",
    "    # Normal\n",
    "    questions = [\n",
    "        \"The following is a graph given as a list of edges:\",\n",
    "        \"\\n\".join([str(e) for e in generated_prompt]),\n",
    "        f\"What is the degree of node {row['vertex']}? Answer with a number without furthur explanations.\"\n",
    "    ]\n",
    "    response = llm_api.ask(questions, god_model)\n",
    "    response = llm_api.take_out_number(response)\n",
    "    gt = graph_utils.get_degree(generated_prompt, row[\"vertex\"])\n",
    "    normal_error = abs(gt - response)\n",
    "    normal_errors.append(normal_error)\n",
    "\n",
    "    if god_model == \"gpt-3.5-turbo\" or row[\"algorithm\"] == \"no_opt\":\n",
    "        exposure_errors.append(normal_error)\n",
    "    else:\n",
    "        # Swap\n",
    "        window = len(generated_prompt) // 10\n",
    "        generated_prompt[:window], generated_prompt[window:2*window] = generated_prompt[window:2*window], generated_prompt[:window]\n",
    "    \n",
    "        questions = [\n",
    "            \"The following is a graph given as a list of edges:\",\n",
    "            \"\\n\".join([str(e) for e in generated_prompt]),\n",
    "            f\"What is the degree of node {row['vertex']}? Answer with a number without furthur explanations.\"\n",
    "        ]\n",
    "        response = llm_api.ask(questions, god_model)\n",
    "        response = llm_api.take_out_number(response)\n",
    "        gt = graph_utils.get_degree(generated_prompt, row[\"vertex\"])\n",
    "        exposure_error = abs(gt - response)\n",
    "        exposure_errors.append(exposure_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"normal_error\"] = normal_errors\n",
    "# data[\"exposure_error\"] = exposure_errors\n",
    "# data.to_csv(\"grpah_new.csv\", index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>edge_size</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>vertex</th>\n",
       "      <th>diff</th>\n",
       "      <th>original_prompt</th>\n",
       "      <th>generated_prompt</th>\n",
       "      <th>god_model</th>\n",
       "      <th>normal_error</th>\n",
       "      <th>exposure_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gemma2:9b</td>\n",
       "      <td>56</td>\n",
       "      <td>naive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...</td>\n",
       "      <td>[[0, 18], [0, 3], [0, 5], [0, 10], [0, 15], [0...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gemma2:9b</td>\n",
       "      <td>56</td>\n",
       "      <td>opt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...</td>\n",
       "      <td>[[0, 18], [0, 3], [0, 5], [0, 10], [0, 15], [0...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gemma2:9b</td>\n",
       "      <td>56</td>\n",
       "      <td>no_opt</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...</td>\n",
       "      <td>[[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gemma2:9b</td>\n",
       "      <td>56</td>\n",
       "      <td>naive</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...</td>\n",
       "      <td>[[0, 5], [5, 17], [3, 5], [5, 19], [5, 15], [5...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gemma2:9b</td>\n",
       "      <td>56</td>\n",
       "      <td>opt</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...</td>\n",
       "      <td>[[0, 5], [5, 17], [3, 5], [5, 19], [5, 15], [5...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model  edge_size algorithm  vertex  diff  \\\n",
       "0  gemma2:9b         56     naive       0     0   \n",
       "1  gemma2:9b         56       opt       0     0   \n",
       "2  gemma2:9b         56    no_opt       0     1   \n",
       "3  gemma2:9b         56     naive       5     1   \n",
       "4  gemma2:9b         56       opt       5     0   \n",
       "\n",
       "                                     original_prompt  \\\n",
       "0  [[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...   \n",
       "1  [[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...   \n",
       "2  [[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...   \n",
       "3  [[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...   \n",
       "4  [[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...   \n",
       "\n",
       "                                    generated_prompt      god_model  \\\n",
       "0  [[0, 18], [0, 3], [0, 5], [0, 10], [0, 15], [0...  gpt-3.5-turbo   \n",
       "1  [[0, 18], [0, 3], [0, 5], [0, 10], [0, 15], [0...  gpt-3.5-turbo   \n",
       "2  [[0, 18], [16, 17], [10, 13], [11, 18], [1, 7]...  gpt-3.5-turbo   \n",
       "3  [[0, 5], [5, 17], [3, 5], [5, 19], [5, 15], [5...  gpt-3.5-turbo   \n",
       "4  [[0, 5], [5, 17], [3, 5], [5, 19], [5, 15], [5...  gpt-3.5-turbo   \n",
       "\n",
       "   normal_error  exposure_error  \n",
       "0             0               0  \n",
       "1             0               0  \n",
       "2             0               0  \n",
       "3             1               1  \n",
       "4             0               0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"graph_result_exposure_aligend.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error(model, god_model):\n",
    "    df = data[(data[\"model\"] == model) \n",
    "                & (data[\"god_model\"] == god_model)]\n",
    "    \n",
    "    df = df[[\"edge_size\", \"algorithm\", \"normal_error\", \"exposure_error\"]]\n",
    "    df = df.groupby([\"edge_size\", \"algorithm\"]).mean().reset_index()\n",
    "    \n",
    "    for algorithm in df[\"algorithm\"].unique():\n",
    "        tmp = df[df[\"algorithm\"] == algorithm]\n",
    "        plt.plot(\n",
    "            [str(x) for x in tmp[\"edge_size\"]],\n",
    "            tmp[\"exposure_error\"],\n",
    "            label=labels[algorithm],\n",
    "            marker=\"o\",\n",
    "            markersize=6\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"# of edges\", fontsize=12)\n",
    "    plt.ylabel(\"Output Error ($\\epsilon_{\\mathcal{L}}$)\", fontsize=12)\n",
    "    plt.title(\"$\\mathcal{H}= $\" + MODEL_NAMES[MODELS.index(model)], fontsize=12);\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "\n",
    "for model_index, model in enumerate(MODELS):\n",
    "    plt.subplot(1, 4, model_index + 1)\n",
    "    plot_error(model, god_model=\"gpt-3.5-turbo\")\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout();\n",
    "# plt.savefig(\"../../figures/graph-output-error-gpt-3.eps\", format=\"eps\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
